import cv2
import os
import numpy as np
from tqdm import tqdm
from random import shuffle
import random as rn
from PIL import Image
import matplotlib.pyplot as plt
from zipfile import ZipFile
from keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import KFold, cross_val_score, train_test_split
from keras import optimizers
from keras.layers import LeakyReLU
from keras.preprocessing.image import ImageDataGenerator, load_img
from keras.callbacks import Callback,ModelCheckpoint
from keras.callbacks import ModelCheckpoint

DIR='M:\\MALARAIA\\scratch\\cell_images\\'
BURNS_DIR='M:\\MALARAIA\\scratch\\cell_images\\Parasitized\\'
HEALTHY_DIR='M:\\MALARAIA\\scratch\\cell_images\\Uninfected\\'
X=[]
Y=[]
IMG_SIZE=32
batch_size=4
epochs=200

def assign_label(img,image_type):
    return image_type

def make_train_data(image_type,DIR):
    for img in tqdm(os.listdir(DIR)):
        label=assign_label(img,image_type)
        path=os.path.join(DIR,img)
        img=cv2.imread(path,cv2.IMREAD_COLOR)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img=cv2.resize(img,(IMG_SIZE,IMG_SIZE))
        X.append(np.array(img))
        Y.append(str(label))

make_train_data('Burns',BURNS_DIR)
#print(len(X))
make_train_data('Healthy',HEALTHY_DIR)
#print("Length of training Data: ",len(X))
#print("Length of training Labels",len(Y))

fig,ax=plt.subplots(5,2)
fig.set_size_inches(15,15)
for i in range(5):
    for j in range(2):
        l=rn.randint(0,len(Y))
        ax[i,j].imshow(X[l])
        ax[i,j].set_title('Image: '+Y[l])
        
plt.tight_layout()
plt.show()

#Label Encoding
le=LabelEncoder()
Y=le.fit_transform(Y)
Y=to_categorical(Y,2)
X=np.array(X)
X=X/255

x_train,x_valid,y_train,y_valid=train_test_split(X,Y,test_size=0.20,random_state=7)
x_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.10,random_state=7)

#Show length of each split
print("Length of training data split ", len(x_train))
print("Length of validation data split ", len(x_valid))
print("Length of testing data split ", len(x_test))

datagen=ImageDataGenerator()
datagen.fit(x_train)




#Initialising the model
model= Sequential()
# Step 1 - Convolution
model.add(Conv2D(filters=64, input_shape = (IMG_SIZE,IMG_SIZE, 3), kernel_size=(3,3),strides=(1,1), activation = 'relu',padding='same'))
model.add(MaxPooling2D(pool_size = (2, 2),strides=(2,2)))
# Adding a second convolutional layer
model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), activation = 'relu',padding='same'))
model.add(MaxPooling2D(pool_size = (2, 2),strides=(2,2)))
# Adding a second convolutional layer
model.add(Conv2D(16, kernel_size=(3,3), strides=(1,1), activation = 'relu',padding='same'))
model.add(GlobalAveragePooling2D())
model.add(Dropout(0.1))
model.add(Dense(2, activation = 'softmax'))
# Compiling the CNN
model.compile(optimizer = optimizers.Adam(lr=0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])
model.summary()

history=model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),
                            epochs=epochs,validation_data=(x_valid,y_valid),verbose=1,
                            steps_per_epoch=x_train.shape[0]//batch_size)



# Plot the accuracy and loss curves
model_acc = history.history['accuracy']
model_val_acc = history.history['val_accuracy']
model_loss = history.history['loss']
model_val_loss = history.history['val_loss']

epochs = range(len(model_acc))

plt.plot(epochs, model_acc, 'black', label='Training accuracy')
plt.plot(epochs, model_val_acc, 'purple', label='Validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.figure()
plt.show()
plt.plot(epochs, model_loss, 'black', label='Training loss')
plt.plot(epochs, model_val_loss, 'purple', label='Validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

print("TESTING THE TRAINED MODEL USING TEST SPLIT")
scores = model.evaluate(x_test, y_test, verbose=1)
print('Test loss:', scores[0])
print('Test accuracy:', scores[1])
